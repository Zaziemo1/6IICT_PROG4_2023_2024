{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#FFFFFF markdown=\"1\">\n",
    "        <h1> <center> Gebaseerd op een cursus van:</center> </h1> \n",
    "    </font>\n",
    "    <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toepassing: ML (lerende) Sentimentanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\">\n",
    "Voor deze notebook te starten. Zorg zeker dat je de inhoud van 2_AI_sentiment.ipynb begrijpt. In deze notebook zal je dezelfde concepten gebruiken. Nu zal echter een ML-model gebruikt worden om de vervelende stappen uit 2_AI_sentiment.ipynb te automatiseren.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algemene info bij Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Modules installeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze notebook zal je de module <a href=\"https://spacy.io/\">**spacy**</a> gebruiken. Deze module bevat een Machine Learning taalmodel. We zullen deze gebruiken om bepaalde stappen van het voorverwerken te vereenvoudigen (zie ook *deel 1.3 'Doel ML Sentimentanalyse'*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Wees zeker dat je rechtsboven in de juiste kernel zit vooraleer spacy te installeren.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp37-cp37m-win_amd64.whl (12.4 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: setuptools in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (47.1.0)\n",
      "Collecting typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp37-cp37m-win_amd64.whl (122 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy>=1.15.0; python_version < \"3.9\"\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp37-cp37m-win_amd64.whl (482 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp37-cp37m-win_amd64.whl (25 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp37-cp37m-win_amd64.whl (39 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.3-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (24.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting zipp>=0.5; python_version < \"3.8\"\n",
      "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting importlib-metadata; python_version == \"3.7\"\n",
      "  Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic-core==2.14.6\n",
      "  Downloading pydantic_core-2.14.6-cp37-none-win_amd64.whl (1.9 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.5-cp37-cp37m-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\venv\\venv_test\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp37-cp37m-win_amd64.whl (6.6 MB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: typing-extensions, zipp, catalogue, cymem, murmurhash, preshed, langcodes, spacy-loggers, annotated-types, importlib-metadata, pydantic-core, pydantic, MarkupSafe, jinja2, smart-open, numpy, srsly, tqdm, click, typer, confection, wasabi, blis, thinc, spacy-legacy, cloudpathlib, weasel, spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pydantic-core 2.14.6 has requirement typing-extensions!=4.7.0,>=4.6.0, but you'll have typing-extensions 4.4.0 which is incompatible.\n",
      "ERROR: pydantic 2.5.3 has requirement typing-extensions>=4.6.1, but you'll have typing-extensions 4.4.0 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 2] The system cannot find the file specified: 'c:\\\\venv\\\\venv_test\\\\Lib\\\\site-packages\\\\srsly\\\\_json_api.py'\n",
      "\n",
      "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\venv\\venv_test\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.7.4-cp37-cp37m-win_amd64.whl (12.4 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (2.5.3)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.8-cp37-cp37m-win_amd64.whl (482 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (24.0)\n",
      "Collecting numpy>=1.15.0; python_version < \"3.9\"\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Using cached thinc-8.2.3-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (47.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\" in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (4.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version == \"3.7\" in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (6.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\venv\\venv_test\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: colorama>=0.4.6; sys_platform == \"win32\" and python_version >= \"3.7\" in c:\\venv\\venv_test\\lib\\site-packages (from wasabi<1.2.0,>=0.9.1->spacy) (0.4.6)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.11-cp37-cp37m-win_amd64.whl (6.6 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in c:\\venv\\venv_test\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.15.0)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Installing collected packages: spacy-legacy, click, typer, srsly, wasabi, numpy, blis, confection, thinc, tqdm, cloudpathlib, weasel, spacy\n",
      "Successfully installed blis-0.7.11 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.4 numpy-1.21.6 spacy-3.7.4 spacy-legacy-3.0.12 srsly-2.4.8 thinc-8.2.3 tqdm-4.66.4 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\venv\\venv_test\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nl-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-3.7.0/nl_core_news_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\venv\\venv_test\\lib\\site-packages (from nl-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: jinja2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: setuptools in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (47.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (1.21.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (24.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.5.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\" in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (4.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\venv\\venv_test\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\venv\\venv_test\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in c:\\venv\\venv_test\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\venv\\venv_test\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\venv\\venv_test\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in c:\\venv\\venv_test\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\venv\\venv_test\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv\\venv_test\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (2.14.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version == \"3.7\" in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (6.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\venv\\venv_test\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.5.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\venv\\venv_test\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->nl-core-news-sm==3.7.0) (0.7.11)\n",
      "Installing collected packages: nl-core-news-sm\n",
      "Successfully installed nl-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('nl_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\venv\\venv_test\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# installeren van spacy (dit kan even duren)\n",
    "!pip3 install spacy\n",
    "# installeren van Nederlandse bibliotheek\n",
    "!python -m spacy download nl_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Herhaling AI Sentimentanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de vorige notebook, 'AI sentimentanalyse', maakte je kennis met de principes van een regelgebaseerde (AI) sentimentanalyse: \n",
    "\n",
    " -  Het maakt gebruik van een **lexicon** of woordenboek met daarin woorden gekoppeld aan hun **sentiment** (positief, negatief of neutraal).\n",
    " -  Voor een sentimentanalyse uit te voeren op een tekst, moet de tekst eerst **voorverwerkt** worden. Veelvoorkomende preprocessing stappen zijn **lowercasing**, **tokenisering**, **woordsoort tagging** en **lemmatisering**.\n",
    " - De sentimentanalyse overloopt de combinatie van woordsoort/lemma voor ieder woord in de tekst. Zit deze in het lexicon? Tel dan de sentimentscore op bij een teller.\n",
    " \n",
    "In de vorige notebook waren nog niet alle stappen geautomatiseerd. **Lemmatisering en woordsoort tagging** moesten manueel gebeuren. Zoals te zien is op onderstaand stappenplan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../_afbeeldingen/AI_sentiment.png\" alt=\"Banner\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 10px; width:80%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Doel ML Sentimentanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze notebook zal je de uitvoer van de sentimentanalyse volledig <b>automatiseren</b>. Je zal m.a.w. de computer al het werk laten doen: de computer zal de data preprocessen (voorverwerken) met het <em>machine learning-model (ML-model) Spacy</em>. Vervolgens zal het via een <em>regelgebaseerd AI-systeem</em> de <b>lemmas/woordsoorten</b> matchen in het lexicon. Tenslotte neemt de AI op basis van de score een beslissing over het sentiment van de gegeven tekst. Onderstaand stappenplan toont het nieuwe proces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../_afbeeldingen/ML_sentiment.png\" alt=\"Banner\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 10px; width:80%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing met Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Modules & variabelen klaarzetten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onderstaande code importeert spacy in deze Notebook. Vervolgens geven we aan welke taalpakket we in spacy willen laden. nl_core_news_sm is het kleinste taalpakket dat voor Nederlands beschikbaar is. Maar ondanks dit heeft het een accuraatheid van 93%!. Anderen zijn <a href=\"https://spacy.io/usage/models\">HIER</a> te vinden.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# importeren van spacy\n",
    "import spacy\n",
    "# inladen van Nederlandse bibliotheek\n",
    "nlp = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naast het model zetten we ook opnieuw de review klaar die we willen voorverwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "review = \"Nieuw concept in Gent, maar dat kan volgens mij toch beter. De meeste cornflakes waren gewoon de basic soorten. Ook wat duur voor de hoeveelheid die je krijgt, vooral met de toppings zijn ze zuinig. En als je ontbijt aanbiedt, geef de mensen dan toch ook wat meer keuze voor hun koffie.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\">\n",
    "Het lijkt misschien valspelen dat we andermans ML-model gebruiken. Maar onthoud dat je als programmeur vooral praktisch (lees lui) moet zijn. Het opstellen van een eigen ML-model voor tekstherkenning is mogelijk, maar zou ons veel tijd kosten. Je moet namelijk over heel veel gelabelde data bezitten. Bedenk dat je voor miljoenen woorden een lemma en woordsoort moet opstellen...\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lowercasing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Merk op dat deze stap identiek is aan 'deel 4.2 Lowercasing' van de vorige notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aller eerste stap is het omzetten van `review` naar kleine letters. Gelukkig is dit ingebouwd in Python! Zet de tekst in de variabele `review` om naar kleine letters (via welke methode?). Sla het resultaat op in de variabele `review_kleineletters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nieuw concept in gent, maar dat kan volgens mij toch beter. de meeste cornflakes waren gewoon de basic soorten. ook wat duur voor de hoeveelheid die je krijgt, vooral met de toppings zijn ze zuinig. en als je ontbijt aanbiedt, geef de mensen dan toch ook wat meer keuze voor hun koffie.\n"
     ]
    }
   ],
   "source": [
    "# zet tekst van de review om naar tekst in kleine letters\n",
    "review_kleineletters = review.lower()\n",
    "\n",
    "# toon resultaat van lowercasing (er mag geen drukletter meer in de review staan)\n",
    "print(review_kleineletters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tokenisering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens moeten we alle woorden in de tekst splitsen en aan een lijst toevoegen.\n",
    "\n",
    "In voorgaande notebook is de **tokenisering** regelgebaseerd uitgevoerd. het **spacy**-model zal dit echter ook voor zijn rekening nemen (samen met **woordsoort tagging** en **lemmatisering**)! Voer onderstaand code-blok uit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# review met kleine letters aan model voeren\n",
    "review_tokens = nlp(review_kleineletters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit was alles. In `review_tokens` kan je de tokens van de review vinden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\"> \n",
    "Merk op dat de leestekens er nu wel bijstaan. Dit is geen probleem. Spacy zal deze ook een correcte woordsoort & lemma geven.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "De print maakt deze notebook zeer lang. Duw bovenaan op de knop 'clear all outputs' om deze terug te verwijderen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nieuw\n",
      "concept\n",
      "in\n",
      "gent\n",
      ",\n",
      "maar\n",
      "dat\n",
      "kan\n",
      "volgens\n",
      "mij\n",
      "toch\n",
      "beter\n",
      ".\n",
      "de\n",
      "meeste\n",
      "cornflakes\n",
      "waren\n",
      "gewoon\n",
      "de\n",
      "basic\n",
      "soorten\n",
      ".\n",
      "ook\n",
      "wat\n",
      "duur\n",
      "voor\n",
      "de\n",
      "hoeveelheid\n",
      "die\n",
      "je\n",
      "krijgt\n",
      ",\n",
      "vooral\n",
      "met\n",
      "de\n",
      "toppings\n",
      "zijn\n",
      "ze\n",
      "zuinig\n",
      ".\n",
      "en\n",
      "als\n",
      "je\n",
      "ontbijt\n",
      "aanbiedt\n",
      ",\n",
      "geef\n",
      "de\n",
      "mensen\n",
      "dan\n",
      "toch\n",
      "ook\n",
      "wat\n",
      "meer\n",
      "keuze\n",
      "voor\n",
      "hun\n",
      "koffie\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Print het token zelf\n",
    "for token in review_tokens:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Woordsoort tagging en Lemmatisering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `review_tokens` zitten niet alleen de **tokens**, maar ook reeds de **woordsoorten** & **lemma's**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# review met kleine letters aan model voeren\n",
    "review_tokens = nlp(review_kleineletters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ\n",
      "NOUN\n",
      "ADP\n",
      "PROPN\n",
      "PUNCT\n",
      "CCONJ\n",
      "PRON\n",
      "AUX\n",
      "ADP\n",
      "PRON\n",
      "ADV\n",
      "ADJ\n",
      "PUNCT\n",
      "DET\n",
      "ADV\n",
      "NOUN\n",
      "AUX\n",
      "ADJ\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "PUNCT\n",
      "ADV\n",
      "PRON\n",
      "ADJ\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "PRON\n",
      "PRON\n",
      "VERB\n",
      "PUNCT\n",
      "ADV\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "AUX\n",
      "PRON\n",
      "ADJ\n",
      "PUNCT\n",
      "CCONJ\n",
      "SCONJ\n",
      "PRON\n",
      "NOUN\n",
      "VERB\n",
      "PUNCT\n",
      "VERB\n",
      "DET\n",
      "NOUN\n",
      "ADV\n",
      "ADV\n",
      "ADV\n",
      "PRON\n",
      "DET\n",
      "NOUN\n",
      "ADP\n",
      "PRON\n",
      "NOUN\n",
      "PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Print de woordsoort tag van elk token\n",
    "for token in review_tokens:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nieuw\n",
      "concept\n",
      "in\n",
      "Gent\n",
      ",\n",
      "maar\n",
      "dat\n",
      "kunnen\n",
      "volgens\n",
      "mij\n",
      "toch\n",
      "goed\n",
      ".\n",
      "de\n",
      "veel\n",
      "cornflakes\n",
      "zijn\n",
      "gewoon\n",
      "de\n",
      "basic\n",
      "soort\n",
      ".\n",
      "ook\n",
      "wat\n",
      "duur\n",
      "voor\n",
      "de\n",
      "hoeveelheid\n",
      "die\n",
      "je\n",
      "krijgen\n",
      ",\n",
      "vooral\n",
      "met\n",
      "de\n",
      "toppings\n",
      "zijn\n",
      "ze\n",
      "zuinig\n",
      ".\n",
      "en\n",
      "als\n",
      "je\n",
      "ontbijt\n",
      "aanbieden\n",
      ",\n",
      "geven\n",
      "de\n",
      "mens\n",
      "dan\n",
      "toch\n",
      "ook\n",
      "wat\n",
      "veel\n",
      "keuze\n",
      "voor\n",
      "hun\n",
      "koffie\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Print de lemma van elk token\n",
    "for token in review_tokens:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\"> \n",
    "Merk op dat <b>spacy</b> de woordsoort in het Engels geeft. Dit is ook de reden waarom het **Lexicon** Engelse afkortingen gebruikt.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 2.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doorloop `review_tokens` en stel twee lijsten op `review_lemmas` en `review_soort`.\n",
    "- De lijst `review_lemmas` bevat alle lemma's (in correcte volgorde).\n",
    "- De lijst `review_soort` bevat de woordsoorten van alle tokens (in correcte volgorde).\n",
    "\n",
    "Print deze lijsten na het opstellen.\n",
    "\n",
    "Als voorbeeld:<br>\n",
    "- `review_voorverwerkt` = \"gent , maar dat kan\" <br>\n",
    "- `review_lemmas` = [\"Gent\", \",\", \"maar\", \"dat\", \"kunnen\"] <br>\n",
    "- `review_soort` = [\"PROPN\", \"PUNCT\", \"CCONJ\", \"PRON\", \"AUX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nieuw', 'concept', 'in', 'Gent', ',', 'maar', 'dat', 'kunnen', 'volgens', 'mij', 'toch', 'goed', '.', 'de', 'veel', 'cornflakes', 'zijn', 'gewoon', 'de', 'basic', 'soort', '.', 'ook', 'wat', 'duur', 'voor', 'de', 'hoeveelheid', 'die', 'je', 'krijgen', ',', 'vooral', 'met', 'de', 'toppings', 'zijn', 'ze', 'zuinig', '.', 'en', 'als', 'je', 'ontbijt', 'aanbieden', ',', 'geven', 'de', 'mens', 'dan', 'toch', 'ook', 'wat', 'veel', 'keuze', 'voor', 'hun', 'koffie', '.']\n",
      "['ADJ', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'CCONJ', 'PRON', 'AUX', 'ADP', 'PRON', 'ADV', 'ADJ', 'PUNCT', 'DET', 'ADV', 'NOUN', 'AUX', 'ADJ', 'DET', 'NOUN', 'NOUN', 'PUNCT', 'ADV', 'PRON', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'PRON', 'VERB', 'PUNCT', 'ADV', 'ADP', 'DET', 'NOUN', 'AUX', 'PRON', 'ADJ', 'PUNCT', 'CCONJ', 'SCONJ', 'PRON', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'DET', 'NOUN', 'ADV', 'ADV', 'ADV', 'PRON', 'DET', 'NOUN', 'ADP', 'PRON', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "review_lemmas = []\n",
    "review_soort  = [] \n",
    "\n",
    "# VUL AAN\n",
    "\n",
    "for token in review_tokens:\n",
    "    review_lemmas.append(token.lemma_)\n",
    "    review_soort.append(token.pos_)\n",
    "\n",
    "\n",
    "# Print aangevuld lijsten\n",
    "print(review_lemmas)\n",
    "print(review_soort)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Ga pas verder als de printen volgend resultaat geven:\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lemma = ['nieuw', 'concept', 'in', 'Gent', ',', 'maar', 'dat', 'kunnen', 'volgens', 'mij', 'toch', 'goed', '.', 'de', 'veel', 'cornflakes', 'zijn', 'gewoon', 'de', 'basic', 'soort', '.', 'ook', 'wat', 'duur', 'voor', 'de', 'hoeveelheid', 'die', 'je', 'krijgen', ',', 'vooral', 'met', 'de', 'toppings', 'zijn', 'ze', 'zuinig', '.', 'en', 'als', 'je', 'ontbijt', 'aanbieden', ',', 'geven', 'de', 'mens', 'dan', 'toch', 'ook', 'wat', 'veel', 'keuze', 'voor', 'hun', 'koffie', '.']\n",
    "review_soort = ['ADJ', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'CCONJ', 'PRON', 'AUX', 'ADP', 'PRON', 'ADV', 'ADJ', 'PUNCT', 'DET', 'ADV', 'NOUN', 'AUX', 'ADJ', 'DET', 'NOUN', 'NOUN', 'PUNCT', 'ADV', 'PRON', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'PRON', 'VERB', 'PUNCT', 'ADV', 'ADP', 'DET', 'NOUN', 'AUX', 'PRON', 'ADJ', 'PUNCT', 'CCONJ', 'SCONJ', 'PRON', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'DET', 'NOUN', 'ADV', 'ADV', 'ADV', 'PRON', 'DET', 'NOUN', 'ADP', 'PRON', 'NOUN', 'PUNCT']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentimentanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modules & Variabelen klaarzetten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik onderstaande code-blok om `lexicon` vanuit lexicondict.json in te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Lexicon inlezen. Deze bevindt zich in lexicondict.json.\n",
    "import json\n",
    "with open(\"lexicondict.json\", \"rb\") as file: \n",
    "    lexicon = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onderstaande code-blok maakt ook `spacy` klaar voor gebruik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# importeren van spacy\n",
    "import spacy\n",
    "#inladen van Nederlandse bibliotheek\n",
    "nlp = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenslotte de review die we willen onderzoeken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "review = \"Nieuw concept in Gent, maar dat kan volgens mij toch beter. De meeste cornflakes waren gewoon de basic soorten. Ook wat duur voor de hoeveelheid die je krijgt, vooral met de toppings zijn ze zuinig. En als je ontbijt aanbiedt, geef de mensen dan toch ook wat meer keuze voor hun koffie.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sentimentanalyse uitvoeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik alle kennis die je in deze en de vorige notebook hebt opgedaan. Voer een sentimentanalyse op de `review`, gebruik makend van **spacy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../_afbeeldingen/ML_sentiment.png\" alt=\"Banner\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 10px; width:80%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nieuw - ADJ : 0.575\n",
      "concept - NOUN : 0\n",
      "in - ADP : combinatue bestaat niet!\n",
      "Gent - PROPN : combinatue bestaat niet!\n",
      ", - PUNCT : combinatue bestaat niet!\n",
      "maar - CCONJ : combinatue bestaat niet!\n",
      "dat - PRON : combinatue bestaat niet!\n",
      "kunnen - AUX : 1.0\n",
      "volgens - ADP : combinatue bestaat niet!\n",
      "mij - PRON : combinatue bestaat niet!\n",
      "toch - ADV : combinatue bestaat niet!\n",
      "goed - ADJ : 0.775\n",
      ". - PUNCT : combinatue bestaat niet!\n",
      "de - DET : combinatue bestaat niet!\n",
      "veel - ADV : combinatue bestaat niet!\n",
      "cornflakes - NOUN : combinatue bestaat niet!\n",
      "zijn - AUX : 0.0\n",
      "gewoon - ADJ : 0.5\n",
      "de - DET : combinatue bestaat niet!\n",
      "basic - NOUN : combinatue bestaat niet!\n",
      "soort - NOUN : combinatue bestaat niet!\n",
      ". - PUNCT : combinatue bestaat niet!\n",
      "ook - ADV : combinatue bestaat niet!\n",
      "wat - PRON : combinatue bestaat niet!\n",
      "duur - ADJ : -1.0666666666666667\n",
      "voor - ADP : 1.0\n",
      "de - DET : combinatue bestaat niet!\n",
      "hoeveelheid - NOUN : combinatue bestaat niet!\n",
      "die - PRON : combinatue bestaat niet!\n",
      "je - PRON : combinatue bestaat niet!\n",
      "krijgen - VERB : 0.0\n",
      ", - PUNCT : combinatue bestaat niet!\n",
      "vooral - ADV : combinatue bestaat niet!\n",
      "met - ADP : combinatue bestaat niet!\n",
      "de - DET : combinatue bestaat niet!\n",
      "toppings - NOUN : combinatue bestaat niet!\n",
      "zijn - AUX : 0.0\n",
      "ze - PRON : combinatue bestaat niet!\n",
      "zuinig - ADJ : 0.0\n",
      ". - PUNCT : combinatue bestaat niet!\n",
      "en - CCONJ : combinatue bestaat niet!\n",
      "als - SCONJ : combinatue bestaat niet!\n",
      "je - PRON : combinatue bestaat niet!\n",
      "ontbijt - NOUN : combinatue bestaat niet!\n",
      "aanbieden - VERB : 1.0\n",
      ", - PUNCT : combinatue bestaat niet!\n",
      "geven - VERB : 1.0\n",
      "de - DET : combinatue bestaat niet!\n",
      "mens - NOUN : 0.0\n",
      "dan - ADV : combinatue bestaat niet!\n",
      "toch - ADV : combinatue bestaat niet!\n",
      "ook - ADV : combinatue bestaat niet!\n",
      "wat - PRON : combinatue bestaat niet!\n",
      "veel - DET : combinatue bestaat niet!\n",
      "keuze - NOUN : combinatue bestaat niet!\n",
      "voor - ADP : 1.0\n",
      "hun - PRON : combinatue bestaat niet!\n",
      "koffie - NOUN : combinatue bestaat niet!\n",
      ". - PUNCT : combinatue bestaat niet!\n",
      "5.783333333333333\n"
     ]
    }
   ],
   "source": [
    "# Voer hier de sentimentanalyse met spacy uit.\n",
    "sentiment_score = 0\n",
    "\n",
    "review_tokens = nlp(review_kleineletters)\n",
    "\n",
    "review_lemmas = []\n",
    "review_soort  = [] \n",
    "for token in review_tokens:\n",
    "    review_lemmas.append(token.lemma_)\n",
    "    review_soort.append(token.pos_)\n",
    "\n",
    "# VUL VERDER AAN\n",
    "sentiment_score = 0\n",
    "\n",
    "aantal = len(review_lemmas)\n",
    "\n",
    "for i in range(aantal):\n",
    "    if review_lemmas[i] in lexicon: \n",
    "       if review_soort[i] in lexicon[review_lemmas[i]]:\n",
    "          print(f\"{review_lemmas[i]} - {review_soort[i]} : {lexicon[review_lemmas[i]][review_soort[i]]}\")\n",
    "          sentiment_score = sentiment_score + lexicon[review_lemmas[i]][review_soort[i]]\n",
    "          continue\n",
    "    \n",
    "    print(f\"{review_lemmas[i]} - {review_soort[i]} : combinatue bestaat niet!\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Print de bekomen sentiment score\n",
    "print(sentiment_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heb je de sentimentanalyse af? Dan kan je onderstaande code-cel gebruiken om een zin te printen bij de bekomen `sentiment_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De sentimentscore van de review is: 5.783333333333333\n",
      "Het sentiment van de review is positief.\n"
     ]
    }
   ],
   "source": [
    "# eindbeslissing voor deze review\n",
    "if sentiment_score > 0:\n",
    "    sentiment = \"positief\"\n",
    "elif sentiment_score == 0:\n",
    "    sentiment = \"neutraal\"\n",
    "elif sentiment_score < 0:\n",
    "    sentiment = \"negatief\"\n",
    "print(f\"De sentimentscore van de review is: {sentiment_score}\")\n",
    "print(\"Het sentiment van de review is \" + sentiment + \".\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 3.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijk volgende reviews. \n",
    "\n",
    "-  Kies er twee uit en lees deze.\n",
    "\n",
    "-  Welk sentiment koppel jij zelf aan deze reviews? <div style=\"background-color:#008000\">\n",
    "    - review 1: Negatief\n",
    "    - review 2: Neutraal\n",
    "</div>\n",
    "\n",
    "-  Voer een sentimentanalyse uit met de ontwikkelde code uit oefen mee 3.1. \n",
    "\n",
    "-  Vergelijk de sentimentscore met je eigen verwachtingen. Komen ze overeen?  <div style=\"background-color:#008000\">\n",
    "    - Antwoord: Half.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sunrisewater is net wat België nodig heeft. Met het obesitasprobleem dat toch wel aan een opmars bezig is, kunnen we alle initiatieven gebruiken om de jeugd weer gewoon water te laten drinken in plaats van die Amerikaanse bucht! Het smaakt geweldig en wat nog beter is, is dat je het gewoon op elke straathoek kan vinden! Echt geweldig! Vooral de pink and yellow is ten zeerste aan te raden.\n",
    "\n",
    ">  Salé & Sucré staat bekend voor zijn super lekkere en originele cocktails, helaas was er geen alcoholvrije variant te verkrijgen. Onze BOB van dienst moest het dan maar bij frisdrank houden.\n",
    "\n",
    ">  Het was superleuk om eens te mogen proeven van de Filipijnse keuken. De gerechten zaten goed in elkaar, de porties waren zeker groot genoeg en de smaken zaten helemaal goed. Voor herhaling vatbaar!\n",
    "\n",
    ">  Gezellige sfeer, lekkere koffie en een mooi interieur. De combinatie van een studiebar en een babbelbar is een geniaal idee! Studeren met een lekker bakkie koffie, een overheerlijk hapje en samen met andere studenten, werkt enorm motiverend. Het interieur is enorm rustgevend met weinig afleiding, waardoor ik nog nooit zoveel heb kunnen doen!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\">\n",
    "Proficiat, je hebt jouw regelgebaseerd (AI) systeem gecombineerd met een lerend (ML) systeem. Hierdoor is de sentimentanalyse volledig geautomatiseerd!\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "  <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "\n",
    "Deze Notebook is gebaseerd op: Notebook Chatbot, zie <a href=\"http://www.aiopschool.be\">AI Op School</a>, van S. Pletinck , F. wyffels & N. Gesquière is in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
